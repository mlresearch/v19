---
title: Bounds on Individual Risk for Log-loss Predictors
abstract: In sequential prediction with log-loss as well as density estimationwith
  risk measured by KL divergence, one is often interested in the\em expected instantaneous
  loss, or, equivalently, the \em  individual risk at a given fixed sample size n.
  For Bayesianprediction and estimation methods, it is often easy to obtain boundson
  the \em cumulative risk. Such results are based on bounding theindividual sequence
  regret, a technique that is very well known in theCOLT community. Motivated by the
  easiness of proofs for the cumulativerisk, our open problem is to use the results
  on cumulative risk to prove corresponding individual-risk bounds.
pdf: http://proceedings.mlr.press/v19/grunwald11b/grunwald11b.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: grunwald11b
month: 0
firstpage: 813
lastpage: 816
page: 813-816
sections: 
author:
- given: Peter D.
  family: Grünwald
- given: Wojciech
  family: Kotłowski
date: 2011-12-21
address: Budapest, Hungary
publisher: PMLR
container-title: Proceedings of the 24th Annual Conference on Learning Theory
volume: '19'
genre: inproceedings
issued:
  date-parts:
  - 2011
  - 12
  - 21
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
