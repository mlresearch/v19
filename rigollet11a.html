<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">

<div id="content">
<h2>Neyman-Pearson classification under a strict constraint</h2>
<p><i><b>Philippe Rigollet, Xin Tong</b></i> ; JMLR W&amp;CP 19:595-614, 2011.</p>

<h3>Abstract</h3>
Motivated by problems of anomaly detection, this paper implements the Neyman-Pearson paradigm to deal with asymmetric errors in binary classification with a convex loss. Given a finite collection of classifiers, we combine them and obtain a new classifier  that satisfies simultaneously the two following properties with high probability: (i), its probability of type~I error is below a pre-specified level and (ii), it has probability of type ~II error close to the minimum possible. The proposed classifier is obtained by minimizing an empirical objective subject to an empirical constraint. The novelty of the method is that the classifier output by this problem is shown to satisfy the original constraint on type~I error. This strict enforcement of the constraint has interesting consequences on the control of the type~II error and we develop new techniques to handle this situation.  Finally, connections with chance constrained optimization are evident and are investigated.
</div>

<hr>
<center>Page last modified on Sat Dec 17 01:07 CET 2011.</center>
